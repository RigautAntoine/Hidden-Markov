{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My implementation of Rabiner's article \"A tutorial on Hidden Markov Models and Selected Applications in Speech Recognition\"\n",
    "\n",
    "\n",
    "\n",
    "Solutions to the three problems of Hidden Markov Models:\n",
    "* Likelihood **evaluation** of a sequence of observations given a fully specified HMM model => Forward-Backward algorithm\n",
    "* Most **\"correct\" state** sequence determination problem, given a sequence of observations and a fully specified model => Viterbi algorithm\n",
    "* **Model training** problem. Specifying the \"best\" model parameters given a set of observed signals => Baum-Welch algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_random_model(N, M):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        N (int): number of unique states\n",
    "        M (int): number of unique observation signals (the signal is a categorical variable)\n",
    "        \n",
    "    Returns:\n",
    "        A (numpy.array N x N): state transition matrix\n",
    "        B (numpy.array N x M): state-observation emission probability matrix\n",
    "        pi (numpy.array N): state initialization probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transition matrix\n",
    "    A = np.random.random(size = (N, N))\n",
    "    A /= A.sum(axis=1).reshape((N, 1))\n",
    "\n",
    "    # Observation emission matrix\n",
    "    B = np.random.random(size = (N, M))\n",
    "    B /= B.sum(axis=1).reshape((N, 1))\n",
    "\n",
    "    # Initial transition probabilities\n",
    "    pi = np.random.random(size = (N,))\n",
    "    pi /= pi.sum()\n",
    "    \n",
    "    return A, B, pi\n",
    "\n",
    "def simulate(model, T):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        model (tuple or list) with elements (in order):\n",
    "            A (numpy.array N x N): state transition matrix\n",
    "            B (numpy.array N x M): state-observation emission probability matrix\n",
    "            pi (numpy.array N): state initialization probabilities\n",
    "        T: sequence length\n",
    "        \n",
    "    Returns:\n",
    "        Q: state sequence simulation\n",
    "        O: observation sequence simulation\n",
    "    \"\"\"\n",
    "    \n",
    "    A, B, pi = model\n",
    "\n",
    "    Q = []\n",
    "    O = []\n",
    "    \n",
    "    # Initialization\n",
    "    q = np.random.choice(np.arange(N), p=pi)\n",
    "    Q.append(q)\n",
    "    O.append(np.random.choice(np.arange(M), p=B[q]))\n",
    "\n",
    "    while len(O) < T:\n",
    "        q = np.random.choice(np.arange(N), p=A[q])\n",
    "        Q.append(q)\n",
    "        O.append(np.random.choice(np.arange(M), p=B[q]))\n",
    "        \n",
    "    return Q, O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #1: Likelihood Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(O, model):\n",
    "    \"\"\"\n",
    "    Implements the forward piece of the Forward-Backward algorithm\n",
    "    \n",
    "    Parameters:\n",
    "        A, B, pi = model\n",
    "        O (list): observation sequence of length T\n",
    "    \n",
    "    Returns:\n",
    "        np.array (N x T)\n",
    "    \"\"\"\n",
    "    \n",
    "    A, B, pi = model\n",
    "\n",
    "    N, _ = B.shape\n",
    "    T = len(O)\n",
    "    \n",
    "    # Keep track within matrix\n",
    "    forw = np.zeros((N, T))\n",
    "    forw[:,0] = B[:,O[0]] * pi # Initial step\n",
    "\n",
    "    # Induction\n",
    "    for t in np.arange(1, T):\n",
    "\n",
    "        forw[:,t] = A.T.dot(forw[:,t-1]) * B[:,O[t]]\n",
    "        \n",
    "    return forw\n",
    "\n",
    "def likelihood(O, model):\n",
    "    \"\"\"\n",
    "    Computes the likelihood of an observation sequence given the model\n",
    "    \"\"\"\n",
    "    return forward(O, model)[:,-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 2, 2, 0, 1, 0, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Model initialization\n",
    "N = 4\n",
    "M = 3\n",
    "T = 10\n",
    "model = initialize_random_model(N, M)\n",
    "\n",
    "# Simulate a random sequence\n",
    "Q, O = simulate(model, T)\n",
    "\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.95223439e-02 4.56452364e-02 1.15566492e-02 5.32089224e-03\n",
      "  1.17636598e-03 3.82518234e-04 6.71270902e-05 2.81288816e-05\n",
      "  8.76442383e-06 4.30961141e-06]\n",
      " [2.17730493e-01 5.43944193e-02 2.86217312e-02 1.12055208e-02\n",
      "  9.09792677e-05 4.75565303e-04 5.74507346e-06 3.26645920e-05\n",
      "  2.11619694e-05 8.98756824e-06]\n",
      " [4.42338580e-02 4.40383686e-02 1.51091919e-02 5.28884243e-03\n",
      "  9.21576299e-04 9.15464987e-04 1.00921680e-04 7.38808816e-05\n",
      "  1.75868438e-05 5.19921345e-06]\n",
      " [1.02527183e-01 3.78549928e-02 1.66437558e-02 6.69353497e-03\n",
      "  2.53785243e-03 3.66881829e-04 1.81087478e-04 2.72965877e-05\n",
      "  1.42518912e-05 5.64139175e-06]]\n"
     ]
    }
   ],
   "source": [
    "forward_matrix = forward(O, model)\n",
    "\n",
    "print(forward_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4137784848116605e-05\n"
     ]
    }
   ],
   "source": [
    "# Likelihood estimate\n",
    "print(likelihood(O, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #2: Most \"correct\" state sequence determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(O, model):\n",
    "    \"\"\"\n",
    "    Implements the Viterbi algorithm\n",
    "    \n",
    "    Parameters:\n",
    "        A, B, pi = model\n",
    "        O (list): observation sequence of length T\n",
    "    \n",
    "    Returns:\n",
    "        list of length T: most likely state sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    A, B, pi = model\n",
    "    N, _ = B.shape\n",
    "    T = len(O)\n",
    "    \n",
    "    # Initialization\n",
    "    ds = np.zeros((N, T))\n",
    "    phis = np.zeros((N, T))\n",
    "    ds[:,0] = B[:,O[0]] * pi\n",
    "\n",
    "    for t in np.arange(1, T):\n",
    "        delta = A.T * ds[:,t-1]\n",
    "        ds[:,t] = np.max(delta, axis=1) * B[:,O[t]]\n",
    "        phis[:,t] = np.argmax(delta, axis=1)\n",
    "\n",
    "    qs = []\n",
    "    s = np.argmax(ds[:,-1])\n",
    "    qs.append(s)\n",
    "\n",
    "    # Backtracking\n",
    "    for i in np.arange(1, T):\n",
    "        s = phis[int(s), -i]\n",
    "        qs.append(int(s))\n",
    "\n",
    "    # Reverse the list\n",
    "    return qs[-1::-1]\n",
    "\n",
    "def state_correctness(Q, O, model):\n",
    "    \"\"\"Evaluate likelihood of state seq Q given observation sequence O and model\"\"\"\n",
    "    \n",
    "    A, B, pi = model\n",
    "    \n",
    "    # Initialization\n",
    "    lik = pi[Q[0]] * B[Q[0], O[0]]\n",
    "    \n",
    "    for qp, q, o in zip(Q[:-1], Q[1:], O[1:]):\n",
    "        lik *= A[qp, q] * B[q, o]\n",
    "        \n",
    "    return lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2, 1, 0, 2, 2, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# True state sequence \n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 3, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Estimate state sequence\n",
    "Qhat = viterbi(O, model)\n",
    "\n",
    "print(Qhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.011425723009036e-10\n",
      "1.7856632367010275e-08\n"
     ]
    }
   ],
   "source": [
    "# Likelihood of the true sequence\n",
    "print(state_correctness(Q, O, model))\n",
    "# Likelihood of the estimated sequence\n",
    "print(state_correctness(Qhat, O, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #3: Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(O, model):\n",
    "    \"\"\"\n",
    "    Implements the backward piece of the Forward-Backward algorithm\n",
    "    \n",
    "    Parameters:\n",
    "        A, B, pi = model\n",
    "        O (list): observation sequence of length T\n",
    "    \n",
    "    Returns:\n",
    "        np.array (N x T)\n",
    "    \"\"\"\n",
    "    \n",
    "    A, B, pi = model\n",
    "    N, _ = B.shape\n",
    "    T = len(O)\n",
    "    \n",
    "    backw = np.zeros((N, T))\n",
    "    backw[:,-1] = 1\n",
    "\n",
    "    # Induction\n",
    "    for t in np.arange(T-2, -1, -1):\n",
    "        backw[:,t] = A.dot(backw[:,t+1]*B[:,O[t+1]])\n",
    "        \n",
    "    return backw\n",
    "\n",
    "def build_eps(model_t, O):\n",
    "    \"\"\"\n",
    "    Epsilon tensor computation (N, N, T)\n",
    "    \"\"\"\n",
    "\n",
    "    A_t, B_t, pi_t = model_t\n",
    "    N, M  = B_t.shape\n",
    "    T = len(O)\n",
    "\n",
    "    # Forward\n",
    "    forw = forward(O, model_t)\n",
    "\n",
    "    # Backward procedure\n",
    "    backw = backward(O, model_t)\n",
    "\n",
    "    # Compute epsilon values as a 3D tensor\n",
    "    eps = np.zeros((N, N, T-1))\n",
    "\n",
    "    for t in range(T-1):\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                eps[i, j, t] = forw[i, t] * A_t[i, j] * B_t[j, O[t+1]] * backw[j, t+1]\n",
    "\n",
    "    # Standardize\n",
    "    eps /= eps.sum(axis=(0, 1))\n",
    "    \n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation\n",
    "n = 5000\n",
    "min_obs_size = 5\n",
    "max_obs_size = 12\n",
    "\n",
    "data = []\n",
    "\n",
    "for _ in range(n):\n",
    "    Q, O = simulate(model, T=np.random.randint(min_obs_size, max_obs_size))\n",
    "    data.append(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization of model parameters\n",
    "\n",
    "A_o, B_o, pi_o = initialize_random_model(N, M)\n",
    "model_o = (A_o, B_o, pi_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better initializing for B\n",
    "\n",
    "# Compute the most likely state sequence based on the original data\n",
    "Qs = [viterbi(O, model_o) for O in data]\n",
    "\n",
    "B_n = np.zeros((N, M))\n",
    "for O, Q in zip(data, Qs):\n",
    "    for o, q in zip(O, Q):\n",
    "        B_n[q, o] += 1\n",
    "\n",
    "B_n = (B_n.T / B_n.sum(axis=1)).T\n",
    "B_n = np.maximum(B_n, 0.06)\n",
    "B_n = (B_n.T / B_n.sum(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40365756 0.36125001 0.23509244]\n",
      " [0.41377374 0.17820069 0.40802557]\n",
      " [0.54276851 0.18252476 0.27470673]\n",
      " [0.3693256  0.22808768 0.40258671]]\n"
     ]
    }
   ],
   "source": [
    "# Random\n",
    "print(B_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14226962 0.77024955 0.08748083]\n",
      " [0.13955184 0.27260674 0.58784142]\n",
      " [0.39424676 0.40056535 0.20518789]\n",
      " [0.05568258 0.05568258 0.88863484]]\n"
     ]
    }
   ],
   "source": [
    "# Better\n",
    "print(B_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-41770.73016975706\n"
     ]
    }
   ],
   "source": [
    "# Final initalized parameters\n",
    "A_i = A_o.copy()\n",
    "B_i = B_n.copy() # Use the new initalized value\n",
    "pi_i = pi_o.copy()\n",
    "\n",
    "model_i = (A_i, B_i, pi_i)\n",
    "\n",
    "# Initial log-likelihood of the data\n",
    "initial_loglik = np.sum([np.log(likelihood(O, model_i)) for O in data])\n",
    "print(initial_loglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-41342.09633499189\n",
      "-41320.27346469552\n",
      "-41304.149009329296\n",
      "-41291.950530236965\n",
      "-41282.51889705635\n",
      "-41275.087261240995\n",
      "-41269.13436569442\n",
      "-41264.297300908365\n",
      "-41260.31786623348\n",
      "-41257.00864055539\n",
      "-41254.23101292127\n",
      "-41251.88066624989\n",
      "-41249.87780809753\n",
      "-41248.160482576895\n",
      "-41246.67991652871\n",
      "-41245.397230229966\n",
      "-41244.281077283595\n",
      "-41243.30592641644\n",
      "-41242.45079293767\n",
      "-41241.69828944669\n",
      "-41241.033906164885\n",
      "-41240.44545852837\n",
      "-41239.922658109426\n",
      "-41239.45677556924\n",
      "-41239.040373078955\n",
      "-41238.667089776274\n",
      "-41238.33146815471\n",
      "-41238.02881237636\n",
      "-41237.75507174025\n",
      "-41237.50674416621\n"
     ]
    }
   ],
   "source": [
    "# Training iterations\n",
    "iterations = 30\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Build all eps\n",
    "    all_eps = [build_eps(model_i, O) for O in data]\n",
    "    \n",
    "    # Pi update\n",
    "    pi_i = np.vstack([eps[:,:,0].sum(axis=1) for eps in all_eps]).sum(axis=0) \n",
    "    pi_i /= pi_i.sum()\n",
    "    \n",
    "    # Transition matrix update\n",
    "    nb_transitions_from_state_i = np.vstack([eps.sum(axis=(1, 2)) for eps in all_eps]).sum(axis=0)\n",
    "\n",
    "    nb_transitions = np.zeros((N, N)) \n",
    "    for eps in all_eps:\n",
    "        nb_transitions += eps.sum(axis=2)\n",
    "\n",
    "    A_i = (nb_transitions.T / nb_transitions_from_state_i).T\n",
    "    \n",
    "    # Emission matrix update\n",
    "    B_i = np.zeros((N, M))\n",
    "    for O, eps in zip(data, all_eps):\n",
    "        for k in np.arange(M):\n",
    "            B_i[:,k] += eps[:,:,np.array(O[:-1]) == k].sum(axis=(1, 2))\n",
    "    B_i = (B_i.T / nb_transitions_from_state_i).T\n",
    "    \n",
    "    # Compilation and evaluation of the updated model\n",
    "    model_i = (A_i, B_i, pi_i)\n",
    "    new_loglik = np.sum([np.log(likelihood(O, model_i)) for O in data])\n",
    "    print(new_loglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
